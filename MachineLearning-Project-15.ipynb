{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "A100"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "15d1ae6dfc164db48c8b7162a8bbdb7e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_4f9aac49e3c04e1f9e30a787fae1941e",
              "IPY_MODEL_b64c24c05b40490bb4befc0c11a5d19a",
              "IPY_MODEL_44f72196b0ff473a88f753274945b23d"
            ],
            "layout": "IPY_MODEL_14d5237595524ec589a6624a8f003703"
          }
        },
        "4f9aac49e3c04e1f9e30a787fae1941e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_94fda466a7f74cb6a4e58c7ae834de2e",
            "placeholder": "​",
            "style": "IPY_MODEL_c6bea218dc404491a74c505f53dc3a09",
            "value": "config.json: "
          }
        },
        "b64c24c05b40490bb4befc0c11a5d19a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cfbb263b012d4a2a93980479f36a1806",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_96f92e418f9c4476bc9a70b1cf1ac5ec",
            "value": 1
          }
        },
        "44f72196b0ff473a88f753274945b23d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9b42ac05ca214c74ba0b29eab7f42df5",
            "placeholder": "​",
            "style": "IPY_MODEL_bd073ca48a9d48a79a941f8facd36477",
            "value": " 1.00k/? [00:00&lt;00:00, 112kB/s]"
          }
        },
        "14d5237595524ec589a6624a8f003703": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "94fda466a7f74cb6a4e58c7ae834de2e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c6bea218dc404491a74c505f53dc3a09": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "cfbb263b012d4a2a93980479f36a1806": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "96f92e418f9c4476bc9a70b1cf1ac5ec": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "9b42ac05ca214c74ba0b29eab7f42df5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bd073ca48a9d48a79a941f8facd36477": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0ba8abf986774ad199d027e73f21c751": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_5b09a13af44d4bca98cefbd4afb46b58",
              "IPY_MODEL_b046bae3da9645539863308128e0d621",
              "IPY_MODEL_f847ee7da81d4aeaab7fbbe6cb0d4ada"
            ],
            "layout": "IPY_MODEL_ffb15495d6b04445a84e6395744f9c28"
          }
        },
        "5b09a13af44d4bca98cefbd4afb46b58": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3afd6a2e1c8d47e2adff3a86c1c62800",
            "placeholder": "​",
            "style": "IPY_MODEL_da745b8823e649368e0d27d702547a2e",
            "value": "pytorch_model.bin: 100%"
          }
        },
        "b046bae3da9645539863308128e0d621": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a5b9b113ecdb4aaeb6148ea7b8bd9684",
            "max": 513302779,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_14aed9634c884171aae8c4826b333197",
            "value": 513302779
          }
        },
        "f847ee7da81d4aeaab7fbbe6cb0d4ada": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_92e474995ba04bd89648da1184a5bea4",
            "placeholder": "​",
            "style": "IPY_MODEL_4723abbc745f4c0dab31390f60de6dcf",
            "value": " 513M/513M [00:02&lt;00:00, 303MB/s]"
          }
        },
        "ffb15495d6b04445a84e6395744f9c28": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3afd6a2e1c8d47e2adff3a86c1c62800": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "da745b8823e649368e0d27d702547a2e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a5b9b113ecdb4aaeb6148ea7b8bd9684": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "14aed9634c884171aae8c4826b333197": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "92e474995ba04bd89648da1184a5bea4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4723abbc745f4c0dab31390f60de6dcf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7bda54ece74249dba6e316f373095856": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a99150a8abf749eaa65907f6074be610",
              "IPY_MODEL_4ac6932bb82d4bb2814e10977a00a94b",
              "IPY_MODEL_f7e96b1f671d47c78e334e70c3734af8"
            ],
            "layout": "IPY_MODEL_f87fa833e8f241138b5398f307564292"
          }
        },
        "a99150a8abf749eaa65907f6074be610": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cc4f058227534012ad18b252db3a8bca",
            "placeholder": "​",
            "style": "IPY_MODEL_9e03c07872b740e9aca21fcd791ceb88",
            "value": "model.safetensors: 100%"
          }
        },
        "4ac6932bb82d4bb2814e10977a00a94b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_69bbf2ca1a27449dba550270aa316c54",
            "max": 513256494,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_9b863e89b08e4d04a2ec5cbe134a978b",
            "value": 513256494
          }
        },
        "f7e96b1f671d47c78e334e70c3734af8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c861b498af18459cbfdec0ee80341611",
            "placeholder": "​",
            "style": "IPY_MODEL_f42afc080ad44699a588e9987534e3e2",
            "value": " 513M/513M [00:02&lt;00:00, 188MB/s]"
          }
        },
        "f87fa833e8f241138b5398f307564292": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cc4f058227534012ad18b252db3a8bca": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9e03c07872b740e9aca21fcd791ceb88": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "69bbf2ca1a27449dba550270aa316c54": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9b863e89b08e4d04a2ec5cbe134a978b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "c861b498af18459cbfdec0ee80341611": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f42afc080ad44699a588e9987534e3e2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers torch pandas openpyxl peft"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZsqpLCsfWcrP",
        "outputId": "f81a9960-b0b3-44c6-cb68-5ca1b0a11189",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.12/dist-packages (4.57.2)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.12/dist-packages (2.9.0+cu126)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (2.2.2)\n",
            "Requirement already satisfied: openpyxl in /usr/local/lib/python3.12/dist-packages (3.1.5)\n",
            "Requirement already satisfied: peft in /usr/local/lib/python3.12/dist-packages (0.18.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from transformers) (3.20.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.36.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from transformers) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (25.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from transformers) (6.0.3)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers) (2025.11.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from transformers) (2.32.4)\n",
            "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.22.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.7.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.12/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch) (4.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch) (1.14.0)\n",
            "Requirement already satisfied: networkx>=2.5.1 in /usr/local/lib/python3.12/dist-packages (from torch) (3.6)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec>=0.8.5 in /usr/local/lib/python3.12/dist-packages (from torch) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.5 in /usr/local/lib/python3.12/dist-packages (from torch) (2.27.5)\n",
            "Requirement already satisfied: nvidia-nvshmem-cu12==3.3.20 in /usr/local/lib/python3.12/dist-packages (from torch) (3.3.20)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.5.0 in /usr/local/lib/python3.12/dist-packages (from torch) (3.5.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: et-xmlfile in /usr/local/lib/python3.12/dist-packages (from openpyxl) (2.0.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.12/dist-packages (from peft) (5.9.5)\n",
            "Requirement already satisfied: accelerate>=0.21.0 in /usr/local/lib/python3.12/dist-packages (from peft) (1.12.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (1.2.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch) (3.0.3)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (2025.11.12)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import glob\n",
        "import json\n",
        "import torch\n",
        "import pandas as pd\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from transformers import PreTrainedTokenizerFast, GPT2LMHeadModel\n",
        "from torch.optim import AdamW\n",
        "from tqdm import tqdm\n",
        "from peft import LoraConfig, get_peft_model, TaskType, PeftModel"
      ],
      "metadata": {
        "id": "pvvjNG7lBWra"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"PyTorch Version: {torch.__version__}\")\n",
        "print(f\"CUDA Available: {torch.cuda.is_available()}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EQua5is0BWtS",
        "outputId": "e8deaae8-a60c-4990-ff54-da1f41508fea"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PyTorch Version: 2.9.0+cu126\n",
            "CUDA Available: True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Loading KoGPT2 model and tokenizer...\")\n",
        "MODEL_NAME = \"skt/kogpt2-base-v2\" #사용할 모델의 이름 저장\n",
        "\n",
        "tokenizer = PreTrainedTokenizerFast.from_pretrained( #모델이 사용할 규칙을 토크나이저를 불러온다.\n",
        "    MODEL_NAME,\n",
        "    bos_token='</s>', eos_token='</s>', unk_token='<unk>',#문장에 시작, 끝, 모르는 단어 처리\n",
        "    pad_token='<pad>', mask_token='<mask>' #길이 맞춤, 학습을 할때 빈칸을 채운다.(실제 사용X)\n",
        ")\n",
        "\n",
        "base_model = GPT2LMHeadModel.from_pretrained(MODEL_NAME) #학습된 가중치 불러오기\n",
        "base_model.resize_token_embeddings(len(tokenizer)) #입력층 크기를 토크나이저의 단어 수에 맞게 조정\n",
        "\n",
        "print(\"Base model loaded.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KCX1kl2YWhr2",
        "outputId": "507bd8d6-86ee-45f2-f069-672a31484bdc",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading KoGPT2 model and tokenizer...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
            "The tokenizer class you load from this checkpoint is 'GPT2Tokenizer'. \n",
            "The class this function is called from is 'PreTrainedTokenizerFast'.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Base model loaded.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lora_config = LoraConfig(\n",
        "    task_type=TaskType.CAUSAL_LM,\n",
        "    inference_mode=False,\n",
        "    r=8,\n",
        "    lora_alpha=32,\n",
        "    lora_dropout=0.1\n",
        ")\n",
        "\n",
        "model = get_peft_model(base_model, lora_config)\n",
        "model.print_trainable_parameters()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CojDnDqLWhqO",
        "outputId": "20484f16-f499-45ad-f35f-d346692046fe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "trainable params: 294,912 || all params: 125,458,944 || trainable%: 0.2351\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class ChatbotDataset(Dataset):\n",
        "    def __init__(self, file_path, tokenizer, dataset_type):\n",
        "        self.tokenizer = tokenizer\n",
        "        self.data = []\n",
        "        self.dataset_type = dataset_type\n",
        "        self.max_len = 256\n",
        "\n",
        "        print(f\"Loading data from: {file_path}\")\n",
        "\n",
        "        # [F]\n",
        "        if self.dataset_type == \"F_BOT\": #봇 타입이 F일때 실행\n",
        "            try: #에러 발생시 예외 처리\n",
        "                print(\"Parsing as F-Bot (JSON)...\")\n",
        "                with open(file_path, \"r\", encoding=\"utf-8\") as f: #지정된 경로에 json파일을 읽는다.\n",
        "                    raw_data = json.load(f) #파일 내용을 처리할 수 있는 데이터로 변환해 변수에 저장\n",
        "\n",
        "                if isinstance(raw_data, dict): #데이터가 {}인지 형태 확인\n",
        "                    raw_data = raw_data.get('data', []) #{}이라면 data키 안의 실제 데이터를 꺼낸다.\n",
        "\n",
        "                count = 0 #대화 쌍을 세기 위해서 0으로 초기화\n",
        "                for item in tqdm(raw_data, desc=\"Processing Data\"):\n",
        "                    try: #예외 처리(데이터에 문제가 발생하면 다음 데이터로 넘어간다.)\n",
        "                        if 'talk' not in item or 'content' not in item['talk']: #데이터에 talk나 content가 없으면 불량 판단\n",
        "                            continue #불량이면 다음 데이터를 가져온다.\n",
        "\n",
        "                        content = item['talk']['content'] #실제대화 내용을 content에 저장\n",
        "                        i = 1 #대화 순서를 번호로 설정\n",
        "                        while True: #한 대화 세션을 모두 찾는다.\n",
        "                            user_key = f\"HS0{i}\" #대화 순서에 따른 사용자 질문 키를 만든다.\n",
        "                            bot_key = f\"SS0{i}\" #대화 순서에 따른 챗봇 답변 키를 만든다.\n",
        "\n",
        "                            if user_key in content and bot_key in content: #답변 키와 질문 키가 둘 다 존재하는지 확인\n",
        "                                q = content[user_key] #실제 질문 내용를 저장\n",
        "                                a = content[bot_key] #실제 답변 내용을 저장\n",
        "                                if q and a: #실제 질문과 답변이 비어있지 않은지 확인\n",
        "                                    formatted = f\"Q: {q}\\nA: {a}{tokenizer.eos_token}\" #Q: 질문 \\n A: 답변 </s>형식 변형\n",
        "                                    self.data.append(formatted) #완성된 학습용 문자열을 최종 데이터 리스트에 추가\n",
        "                                    count += 1 #카운터 증가\n",
        "                                i += 1 #대화 순서 증가\n",
        "                            else:\n",
        "                                break #대화 턴이 없으면 종료\n",
        "                    except:\n",
        "                        continue\n",
        "\n",
        "                print(f\"Successfully loaded {count} dialogue pairs.\")\n",
        "\n",
        "            except Exception as e: #예외 처리\n",
        "                print(f\"Critical Error parsing F-Bot data: {e}\") #오류 출력\n",
        "\n",
        "        # [T]\n",
        "        elif self.dataset_type == \"T_BOT\": #봇 타입이 T일때 실행\n",
        "            search_pattern = os.path.join(file_path, \"**\", \"*.json\") #지정된 폴더에서 하위 폴더에 있는 모든 json파일 경로로 지정\n",
        "            json_files = glob.glob(search_pattern, recursive=True) #모든 json파일을 찾아서 리스트로 저장\n",
        "            for json_file in tqdm(json_files, desc=\"Parsing T-Bot files\"): #파일 목록을 하나씩 꺼낸다.\n",
        "                try: #예외 처리\n",
        "                    with open(json_file, \"r\", encoding=\"utf-8\") as f: #파일을 모두 읽기 모드로 연다.\n",
        "                        raw_data = json.load(f) #json 내용을 데이터로 변환\n",
        "                    if 'paragraph' in raw_data: #심리상담 데이터의 paragraph키가 있는지 확인\n",
        "                        dialogue = raw_data['paragraph'] #대화 내용이 담긴 리스트를 가져온다.\n",
        "                        for i in range(len(dialogue) - 1): #마지막 턴은 답변이 없으므로 -1을 한다.\n",
        "                            curr = dialogue[i] #현재 대화\n",
        "                            next_t = dialogue[i+1] #다음 대화\n",
        "                            if curr.get('paragraph_speaker') == \"내담자\" and next_t.get('paragraph_speaker') == \"상담사\": #질문자가 내담자이고 답변자가 상담자인 경우만 추출\n",
        "                                q = curr.get('paragraph_text') #내담자(질문) 추출\n",
        "                                a = next_t.get('paragraph_text') #상담자(답변) 추출\n",
        "                                if q and a: #실제 질문과 답변이 비어있지 않은지 확인\n",
        "                                    formatted = f\"Q: {q}\\nA: {a}{tokenizer.eos_token}\" #Q: 질문 \\n A: 답변 </s>형식 변형\n",
        "                                    self.data.append(formatted)#완성된 학습용 문자열을 최종 데이터 리스트에 추가\n",
        "                except:\n",
        "                    pass #파일에 에러가 나면 다음 파일로 넘어간다.\n",
        "\n",
        "        print(f\"Total processed data entries: {len(self.data)}\")\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        text = self.data[idx]\n",
        "        tokens = self.tokenizer(\n",
        "            text, padding=\"max_length\", truncation=True,\n",
        "            max_length=self.max_len, return_tensors=\"pt\"\n",
        "        )\n",
        "        return {\n",
        "            \"input_ids\": tokens[\"input_ids\"].squeeze(),\n",
        "            \"attention_mask\": tokens[\"attention_mask\"].squeeze()\n",
        "        }"
      ],
      "metadata": {
        "id": "6fy5OeHEWhou"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def __len__(self):\n",
        "        return len(self.data)"
      ],
      "metadata": {
        "id": "6pw8gMxPWhnO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def __getitem__(self, idx):\n",
        "        text = self.data[idx]\n",
        "        tokens = self.tokenizer(\n",
        "            text, padding=\"max_length\", truncation=True,\n",
        "            max_length=self.max_len, return_tensors=\"pt\"\n",
        "        )\n",
        "        return {\n",
        "            \"input_ids\": tokens[\"input_ids\"].squeeze(),\n",
        "            \"attention_mask\": tokens[\"attention_mask\"].squeeze()\n",
        "        }"
      ],
      "metadata": {
        "id": "0wpB0imlWhle"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "BOT_TYPE = \"F_BOT\"   # F봇 학습 시\n",
        "#BOT_TYPE = \"T_BOT\"   # T봇 학습 시\n",
        "\n",
        "DRIVE_BASE_PATH = \"/content/drive/My Drive/Dataset\"\n",
        "MODEL_SAVE_DIR = \"/content/drive/My Drive/Dataset\"\n",
        "\n",
        "if BOT_TYPE == \"F_BOT\":\n",
        "    DATA_FILE_PATH = os.path.join(DRIVE_BASE_PATH, \"감성대화말뭉치(최종데이터)_Training.json\")\n",
        "    SAVE_MODEL_PATH = os.path.join(MODEL_SAVE_DIR, \"kogpt2_F_bot_LoRA\")\n",
        "else:\n",
        "    DATA_FILE_PATH = os.path.join(DRIVE_BASE_PATH, \"라벨링데이터\")\n",
        "    SAVE_MODEL_PATH = os.path.join(MODEL_SAVE_DIR, \"kogpt2_T_bot_LoRA\")\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "learning_rate = 3e-5\n",
        "epochs = 3\n",
        "batch_size = 4"
      ],
      "metadata": {
        "id": "I5o_jeArWqH2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train(model, dataset, optimizer, device):\n",
        "    dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
        "    model.to(device)\n",
        "\n",
        "    print(f\"Starting training for {BOT_TYPE}...\")\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        model.train() #학습 모드 전환\n",
        "        total_loss = 0 #손실 초기화\n",
        "        progress_bar = tqdm(dataloader, desc=f\"Epoch {epoch+1}/{epochs}\") #진행률 표시\n",
        "\n",
        "        for batch in progress_bar: #데이터를 batch씩 꺼내와 학습 진행\n",
        "            input_ids = batch['input_ids'].to(device) #질문과 답변이 숫자로 변환된 데이터를 GPU로 옮긴다.\n",
        "            attention_mask = batch['attention_mask'].to(device)\n",
        "            labels = input_ids.clone() #입력 데이터 복사본을 정답으로 사용\n",
        "\n",
        "            optimizer.zero_grad() #기울기 초기화\n",
        "\n",
        "            outputs = model( #순전파 진행\n",
        "                input_ids=input_ids,\n",
        "                attention_mask=attention_mask,\n",
        "                labels=labels\n",
        "            )\n",
        "\n",
        "            loss = outputs.loss #오차 계산\n",
        "            loss.backward() #역전파 진행\n",
        "            optimizer.step() #기울기를 바탕으로 가중치를 업데이트\n",
        "\n",
        "            total_loss += loss.item() #전체 오차를 구한다.\n",
        "            progress_bar.set_postfix({'loss': loss.item()}) #진행률 표시\n",
        "\n",
        "        avg_loss = total_loss / len(dataloader) #평균 오차 계산\n",
        "        perplexity = torch.exp(torch.tensor(avg_loss)).item() #퍼플렉시티 계\n",
        "        print(f\"Epoch {epoch+1}/{epochs} | Avg Loss: {avg_loss:.4f} | Perplexity: {perplexity:.2f}\")\n",
        "\n",
        "    print(\"Training finished.\")"
      ],
      "metadata": {
        "id": "dVsNiaCPWqFu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "try:\n",
        "    from google.colab import drive\n",
        "    drive.mount('/content/drive')\n",
        "    print(\"Google Drive mounted.\")\n",
        "    os.makedirs(MODEL_SAVE_DIR, exist_ok=True)\n",
        "except ImportError:\n",
        "    print(\"Not in Colab.\")\n",
        "\n",
        "try:\n",
        "    dataset = ChatbotDataset(DATA_FILE_PATH, tokenizer, BOT_TYPE)\n",
        "\n",
        "    if len(dataset) > 0:\n",
        "        optimizer = AdamW(model.parameters(), lr=learning_rate)\n",
        "\n",
        "        train(model, dataset, optimizer, device)\n",
        "\n",
        "        print(f\"Saving LoRA model to {SAVE_MODEL_PATH}...\")\n",
        "        model.save_pretrained(SAVE_MODEL_PATH)\n",
        "        tokenizer.save_pretrained(SAVE_MODEL_PATH)\n",
        "        print(\"LoRA Model saved successfully!\")\n",
        "    else:\n",
        "        print(\"ERROR: Dataset is empty. Check your file paths.\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"An error occurred: {e}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6YXgyXYMWtfu",
        "outputId": "1960953b-476a-4c19-87c7-2c19d3299845"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Google Drive mounted.\n",
            "Loading data from: /content/drive/My Drive/Dataset/감성대화말뭉치(최종데이터)_Training.json\n",
            "Parsing as F-Bot (JSON)...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing Data: 100%|██████████| 51628/51628 [00:00<00:00, 115508.98it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Successfully loaded 145948 dialogue pairs.\n",
            "Total processed data entries: 145948\n",
            "Starting training for F_BOT...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1/3: 100%|██████████| 36487/36487 [31:15<00:00, 19.46it/s, loss=0.371]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/3 | Avg Loss: 0.4074 | Perplexity: 1.50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 2/3: 100%|██████████| 36487/36487 [31:16<00:00, 19.45it/s, loss=0.4]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2/3 | Avg Loss: 0.3624 | Perplexity: 1.44\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 3/3: 100%|██████████| 36487/36487 [31:20<00:00, 19.40it/s, loss=0.331]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 3/3 | Avg Loss: 0.3585 | Perplexity: 1.43\n",
            "Training finished.\n",
            "Saving LoRA model to /content/drive/My Drive/Dataset/kogpt2_F_bot_LoRA...\n",
            "LoRA Model saved successfully!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def chat(model_path, user_input):\n",
        "    if not os.path.exists(model_path):\n",
        "        return \"모델 파일이 없습니다.\"\n",
        "\n",
        "    print(\"Loading LoRA model for chat...\")\n",
        "\n",
        "    base = GPT2LMHeadModel.from_pretrained(MODEL_NAME)\n",
        "    lora_model = PeftModel.from_pretrained(base, model_path)\n",
        "\n",
        "    tokenizer = PreTrainedTokenizerFast.from_pretrained(model_path)\n",
        "    lora_model.to(device)\n",
        "    lora_model.eval()\n",
        "\n",
        "    prompt = f\"Q: {user_input}\\nA:\"\n",
        "    input_ids = tokenizer.encode(prompt, return_tensors='pt').to(device)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        output = lora_model.generate(\n",
        "            input_ids, max_length=128, pad_token_id=tokenizer.pad_token_id,\n",
        "            eos_token_id=tokenizer.eos_token_id, do_sample=True,\n",
        "            top_p=0.95, top_k=50, repetition_penalty=1.2\n",
        "        )\n",
        "\n",
        "    text = tokenizer.decode(output[0], skip_special_tokens=True)\n",
        "    try:\n",
        "        return text.split(\"A:\")[1].strip()\n",
        "    except:\n",
        "        return text"
      ],
      "metadata": {
        "id": "QmIPecPtWteF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"\\n--- {BOT_TYPE} Chat Test ---\")\n",
        "try:\n",
        "    test_inputs = [\n",
        "        \"오늘 너무 우울해서 아무것도 하기 싫어\",\n",
        "        \"요즘 잠을 잘 못 자는 것 같아\",\n",
        "        \"미래가 너무 불안해\"\n",
        "    ]\n",
        "\n",
        "    for q in test_inputs:\n",
        "        print(f\"나: {q}\")\n",
        "        print(f\"봇: {chat(SAVE_MODEL_PATH, q)}\\n\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"Test Error: {e}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t9tVJwOCWtZG",
        "outputId": "d7cb43c0-9537-4933-ac67-ef31b8e6f289"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- F_BOT Chat Test ---\n",
            "나: 오늘 너무 우울해서 아무것도 하기 싫어\n",
            "Loading LoRA model for chat...\n",
            "봇: 많이 힘드시겠어요. 그 기분을 어떻게 전할 수 있을까요?\n",
            "\n",
            "나: 요즘 잠을 잘 못 자는 것 같아\n",
            "Loading LoRA model for chat...\n",
            "봇: 어떻게 하는 것이 가장 좋은 방법일까요?\n",
            "\n",
            "나: 미래가 너무 불안해\n",
            "Loading LoRA model for chat...\n",
            "봇: 미래에 대해서 걱정이 많으시군요.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "try:\n",
        "    import peft\n",
        "except ImportError:\n",
        "    !pip install transformers torch peft\n",
        "\n",
        "import torch\n",
        "import os\n",
        "from transformers import PreTrainedTokenizerFast, GPT2LMHeadModel\n",
        "from peft import PeftModel\n",
        "from google.colab import drive\n",
        "\n",
        "# 2. 구글 드라이브 연결\n",
        "try:\n",
        "    drive.mount('/content/drive')\n",
        "except:\n",
        "    print(\"이미 연결되어 있거나 로컬 환경입니다.\")\n",
        "\n",
        "# 3. 설정\n",
        "BASE_PATH = \"/content/drive/My Drive/Dataset\"\n",
        "F_BOT_PATH = os.path.join(BASE_PATH, \"kogpt2_F_bot_LoRA\")\n",
        "T_BOT_PATH = os.path.join(BASE_PATH, \"kogpt2_T_bot_LoRA\")\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "MODEL_NAME = \"skt/kogpt2-base-v2\"\n",
        "\n",
        "print(\"시스템 초기화 중... (베이스 모델 로딩)\")\n",
        "\n",
        "try:\n",
        "    base_model = GPT2LMHeadModel.from_pretrained(MODEL_NAME)\n",
        "    base_model.to(device)\n",
        "    print(\"베이스 모델 준비 완료!\")\n",
        "except Exception as e:\n",
        "    print(f\"베이스 모델 로드 실패: {e}\")\n",
        "    exit()\n",
        "\n",
        "def get_chatbot(mode):\n",
        "    if mode == \"F\":\n",
        "        target_path = F_BOT_PATH\n",
        "        name = \"F-Bot (공감형)\"\n",
        "    else:\n",
        "        target_path = T_BOT_PATH\n",
        "        name = \"T-Bot (상담형)\"\n",
        "\n",
        "    if not os.path.exists(target_path):\n",
        "        print(f\"오류: {target_path} 경로에 모델이 없습니다.\")\n",
        "        return None, None\n",
        "\n",
        "    print(f\"\\n[{name}] 로 장착 중...\")\n",
        "    model = PeftModel.from_pretrained(base_model, target_path)\n",
        "    tokenizer = PreTrainedTokenizerFast.from_pretrained(target_path)\n",
        "    model.eval()\n",
        "    return model, tokenizer\n",
        "\n",
        "def chat_system():\n",
        "    print(\"\\n\" + \"=\"*40)\n",
        "    print(\"MBTI 성향 전환 챗봇 (F ↔ T)\")\n",
        "    print(\"명령어: '!변경'으로 성격 전환, '!종료'로 끝내기\")\n",
        "    print(\"=\"*40)\n",
        "\n",
        "    current_mode = \"F\" #초가에는 F(공감형)로 설정\n",
        "    model, tokenizer = get_chatbot(current_mode) #토그나이저를 불러온다.\n",
        "    if model is None: return\n",
        "\n",
        "    while True:\n",
        "        bot_label = \"F(공감)\" if current_mode == \"F\" else \"T(상담)\" #F(공감)또는 T(상담)선택\n",
        "        user_input = input(f\"\\n👤 나: \") #사용자가 입력한 내용을 저장\n",
        "\n",
        "        if user_input.strip() in [\"!종료\", \"!quit\", \"종료\"]: #종료 명령어 입력시에 상담 종료\n",
        "            print(\"대화를 종료합니다.\")\n",
        "            break\n",
        "\n",
        "        if user_input.strip() in [\"!변경\", \"!switch\", \"변경\"]: #성격 변경 명령어 입력시 성격 변환\n",
        "            current_mode = \"T\" if current_mode == \"F\" else \"F\"\n",
        "            print(f\"\\n성격을 전환합니다! ({'F' if current_mode=='T' else 'T'} -> {current_mode})\")\n",
        "            model, tokenizer = get_chatbot(current_mode)\n",
        "            continue\n",
        "\n",
        "        if not user_input: continue\n",
        "\n",
        "        prompt = f\"Q: {user_input}\\nA:\" #학습 사용한 형식으로 변경해 답변 준비\n",
        "        input_ids = tokenizer.encode(prompt, return_tensors='pt').to(device) #질문을 숫자로 변환\n",
        "\n",
        "        with torch.no_grad():\n",
        "            output = model.generate(\n",
        "                input_ids,\n",
        "                max_length=256,\n",
        "                min_length=32,\n",
        "                pad_token_id=tokenizer.pad_token_id,\n",
        "                eos_token_id=tokenizer.eos_token_id,\n",
        "                do_sample=True,\n",
        "                top_k=50,\n",
        "                top_p=0.92,\n",
        "                repetition_penalty=1.1,\n",
        "                no_repeat_ngram_size=3,\n",
        "                temperature=0.7\n",
        "            )\n",
        "\n",
        "        text = tokenizer.decode(output[0], skip_special_tokens=True) #숫자를 다시 텍스트로 변환\n",
        "        try:\n",
        "            response = text.split(\"A:\")[-1].strip() #실제 답변만 잘라낸다.\n",
        "        except:\n",
        "            response = text\n",
        "\n",
        "        response = response.replace(\"NAME\", \"사용자\") #답변에 있는 단어를 교체\n",
        "        response = response.replace(\"name\", \"사용자\")\n",
        "        response = response.replace(\"PLACE\", \"챗봇\")\n",
        "        response = response.replace(\"place\", \"챗봇\")\n",
        "\n",
        "        print(f\"🤖 {bot_label} 봇: {response}\") #답변 출력\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    chat_system()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "15d1ae6dfc164db48c8b7162a8bbdb7e",
            "4f9aac49e3c04e1f9e30a787fae1941e",
            "b64c24c05b40490bb4befc0c11a5d19a",
            "44f72196b0ff473a88f753274945b23d",
            "14d5237595524ec589a6624a8f003703",
            "94fda466a7f74cb6a4e58c7ae834de2e",
            "c6bea218dc404491a74c505f53dc3a09",
            "cfbb263b012d4a2a93980479f36a1806",
            "96f92e418f9c4476bc9a70b1cf1ac5ec",
            "9b42ac05ca214c74ba0b29eab7f42df5",
            "bd073ca48a9d48a79a941f8facd36477",
            "0ba8abf986774ad199d027e73f21c751",
            "5b09a13af44d4bca98cefbd4afb46b58",
            "b046bae3da9645539863308128e0d621",
            "f847ee7da81d4aeaab7fbbe6cb0d4ada",
            "ffb15495d6b04445a84e6395744f9c28",
            "3afd6a2e1c8d47e2adff3a86c1c62800",
            "da745b8823e649368e0d27d702547a2e",
            "a5b9b113ecdb4aaeb6148ea7b8bd9684",
            "14aed9634c884171aae8c4826b333197",
            "92e474995ba04bd89648da1184a5bea4",
            "4723abbc745f4c0dab31390f60de6dcf",
            "7bda54ece74249dba6e316f373095856",
            "a99150a8abf749eaa65907f6074be610",
            "4ac6932bb82d4bb2814e10977a00a94b",
            "f7e96b1f671d47c78e334e70c3734af8",
            "f87fa833e8f241138b5398f307564292",
            "cc4f058227534012ad18b252db3a8bca",
            "9e03c07872b740e9aca21fcd791ceb88",
            "69bbf2ca1a27449dba550270aa316c54",
            "9b863e89b08e4d04a2ec5cbe134a978b",
            "c861b498af18459cbfdec0ee80341611",
            "f42afc080ad44699a588e9987534e3e2"
          ]
        },
        "id": "8gZ4XpyHMWTo",
        "outputId": "6611f86d-8af3-4f45-84cb-88c779f9f703"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "시스템 초기화 중... (베이스 모델 로딩)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "15d1ae6dfc164db48c8b7162a8bbdb7e"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "pytorch_model.bin:   0%|          | 0.00/513M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "0ba8abf986774ad199d027e73f21c751"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/513M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "7bda54ece74249dba6e316f373095856"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "베이스 모델 준비 완료!\n",
            "\n",
            "========================================\n",
            "MBTI 성향 전환 챗봇 (F ↔ T)\n",
            "명령어: '!변경'으로 성격 전환, '!종료'로 끝내기\n",
            "========================================\n",
            "\n",
            "[F-Bot (공감형)] 로 장착 중...\n",
            "\n",
            "👤 나: 나 힘들어\n",
            "🤖 F(공감) 봇: 어떻게 해야 지금의 상황을 극복할 수 있을까요?  어머님께서 왜 그렇게 말씀하세요? 앞으로 어떤 노력을 하셨나요?\n",
            "\n",
            "👤 나: 요즘 공부때문에 힘들어\n",
            "🤖 F(공감) 봇: 어떻게 해야 하는지 구체적으로 말씀해 주실 수 있을까요? ? 뭘 하면 좋을까요!\n",
            "\n",
            "👤 나: 공부때문에 스트에스를 받아\n",
            "🤖 F(공감) 봇: 공부를 열심히 해야 해서 스트레스가 많으시군요. 어떻게 하면 좋을까요?\n",
            "\n",
            "👤 나: !변경\n",
            "\n",
            "성격을 전환합니다! (F -> T)\n",
            "\n",
            "[T-Bot (상담형)] 로 장착 중...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/peft/tuners/tuners_utils.py:282: UserWarning: Already found a `peft_config` attribute in the model. This will lead to having multiple adapters in the model. Make sure to know what you are doing!\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "👤 나: 나 공부 때문에 스트에스를 받아\n",
            "🤖 T(상담) 봇: 네, 네. 근데 이제 그게 어떤 스트레스를 받거나 이렇게 사용자 님한테 이걸 또 어떻게 해소해 주고 있는지 궁금하신 분들도 계시고요.\n",
            "\n",
            "👤 나: 나 다이어트를 해야되는데 힘들어서 못하겠어\n",
            "🤖 T(상담) 봇: 네, 네. 그러니까 이번에 이제 사용자 씨가 좀 많이 하셨던 것 같아요. 그래서 저도 조금 이렇게 좀 그런 생각이 들었거든요.\n",
            "\n",
            "👤 나: 나 요즘 우울해서 어떻게 해야 할 지 모르겠어\n",
            "🤖 T(상담) 봇: 너무 힘들어. 내가 뭔가 나를 좀 불안하게 만드는 거야. 내가 이거 안 해볼까, 지금?\n",
            "\n",
            "👤 나: 요즘 너무 불안해\n",
            "🤖 T(상담) 봇: 지금 불안하고 좀 긴장되고 좀 불안할 수 있는 상황인 것 같아요. 그런 상황을 좀 어떤 거를 통해서 이제 이렇게 좀 찾아보시고 어떻게 좀 이거를 내가 잘 대처할 수 있을까 이런 것들 한번 생각을 해 보시면 좋을 것 같아요?\n",
            "\n",
            "👤 나: 요즘 너무 우울해\n",
            "🤖 T(상담) 봇: 그러니까요? 사용자 님. 이게 이제 제가 이제 상담을 하다 보니까 사실 상담이 좀 이렇게 되게 좀 힘든 게 이게 우리 이제 그 상담이 이제 너무 힘들고 힘들거든요.\n",
            "\n",
            "👤 나: 요즘 너무 술을 많이 먹어\n",
            "🤖 T(상담) 봇: 그래요. 그럼 그게 이제 그게 내가 스트레스를 받으면 되게 좀 그게 이게 스트레스가 돼 가지고 뭔가 그렇게 좀 그런 것들을 좀 더 해야 되는데 그러지 못하시는 거죠?\n",
            "\n",
            "👤 나: 담배를 못 끊겟어\n",
            "🤖 T(상담) 봇: 그러니까 담배는 안 끊는다라고 말씀하셨을 때 사용자 님한테 물어봤더니 담배를 끊으세요?\n",
            "\n",
            "👤 나: 술을 못끊겠어\n",
            "🤖 T(상담) 봇: 그렇죠. 술이 없으세요? 술도 안하고. 그러면 내가 주정을 안하는 거예요.\n",
            "\n",
            "👤 나: !변경\n",
            "\n",
            "성격을 전환합니다! (T -> F)\n",
            "\n",
            "[F-Bot (공감형)] 로 장착 중...\n",
            "\n",
            "👤 나: 요즘 너무 불안해\n",
            "🤖 F(공감) 봇: 어떻게 해야 불안을 해소할 수 있을까요?   뭔가 변화가 필요한가요?\n",
            "\n",
            "👤 나: 머리가 아파\n",
            "🤖 F(공감) 봇: 머리가 아프시군요. 앞으로 어떻게 하는 것이 좋을까요?  ーダダダで出会談事郎出会議たる意思님을 모시게 되면 좋겠어요.\n",
            "\n",
            "👤 나: 힘들어\n",
            "🤖 F(공감) 봇: 어떻게 하면 지금 상황을 이겨낼 수 있을까요?   뭘 할 수 있을지 고민이 많으시겠어요.\n",
            "\n",
            "👤 나: !변경\n",
            "\n",
            "성격을 전환합니다! (F -> T)\n",
            "\n",
            "[T-Bot (상담형)] 로 장착 중...\n",
            "\n",
            "👤 나: 힘들어\n",
            "🤖 T(상담) 봇: 네. 그럼 어떻게 하면 좋을까요? 이거 하고 싶은데 왜 해야 되는 거죠? 그리고 지금 사용자 님이 좀 더 좋은 컨텐츠를 만들어주고 싶다라는 생각을 해보세요. 네, 감사합니다.\n",
            "\n",
            "👤 나: 머리가 아파\n",
            "🤖 T(상담) 봇: 머리가 아프고. 그러니까 머리도 아프고 또 좀 불안하기도 하고요. 제가 그래서 그거를 이제 말씀드리려고 하는데 그게 좀 다른 문제 때문에 사용자 님께서 이걸 더 잘 아시잖아요.\n",
            "\n",
            "👤 나: !종료\n",
            "대화를 종료합니다.\n"
          ]
        }
      ]
    }
  ]
}